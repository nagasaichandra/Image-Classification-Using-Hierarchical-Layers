{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIVk0n3-F31g",
        "colab_type": "text"
      },
      "source": [
        "# **Image Classification using Hierarchical Layers**\n",
        "Marcus Karr, Teja Kalavakolanu, Nagasai Chandra, Roxanne Miller, Justin \n",
        "Morgan \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TrhXdcEGTWx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPa6mwd8o7Bb",
        "colab_type": "text"
      },
      "source": [
        "**Attention**: refactored a lot of the code to make things cleaner, and because of issues with misaligned cells, redefined functions, and mutated data. The original, more notebook-y workspace version with pictures is [here](https://drive.google.com/open?id=19iPc5Gq0hg3yVuc2ItWfiTftXflM-eaN). Be aware it's not currently set up for all cells to run in sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Lz0IMTG93F",
        "colab_type": "text"
      },
      "source": [
        "**Overview:**\n",
        "This project aims to improve the classification of images by using layers that encode hierarchical information. Traditional convolutional neural networks are trained as flat N-way classifiers, which ignores the hierarchical structure of categories. The new architecture will take the output of ResNet18 and feed it into two separate linear layers. The information from one of these layers will go through subsequent layers and be used to predict the parent class. Information the other will be combined with the output of the parent class prediction in order to predict the child class. \n",
        "\n",
        "The goal of the project is to have the neural network trained on a variety of parent and child classes so that it can easily learn new child classes. To add a new child class we would retrain only a few layers on a minimal number of images. Ideally we could take a some pictures of someone's personal item and retrain our neural net in a relatively short time to recognize that specific item. We believe with this architecture we can achieve a higher level of acccuracy on identifying child classes than current architectures achieve. We also think that we will be able to speed up the training process, use a small number of training images, and still achieve high accuracy with sample efficiency.\n",
        "\n",
        "The architecture can be seen using the links in the \"Changes in Design\" section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAGaPc-8ISkC",
        "colab_type": "text"
      },
      "source": [
        "**Technologies, Tools, Languages, Environment:** \n",
        "We are using pytorch to build the proposed neural nework architecture. Pytorch is a library built for machine learning and makes it easy to implement a variety of neural network architectures. In addition we plan to use the FastAI library for scraping data. FastAI is built on pytorch and abstracts away some of the more technical details of pytorch. So far, we have primarily used it for getting the images of cats and dogs this prototype model was trained on. In the future we may use it to find additional datasets when expanding our model to recognize more than jsut dogs and cats. We are using the Google Colab environment to run our neural network model. The programming language we use is python and pytorch is built on python. In addition python libraries like matplotlib and numpy are also used. Nvida cuda GPU is used to train the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsAyMQcbM5kg",
        "colab_type": "text"
      },
      "source": [
        "**User interaction**\n",
        "run all the cells in the colab in the  order to execute and fetch the results. if downloading resenet 18 weights fail then download it manually and upload to colab to continue the execution. The final demo might be a web app where you can enter a sub class of an object and its label and run the model. The model will be able to predict the new sub class with less images there by achieving sample efficiency as well as the higher accuracy. To train the model you require a GPU but to make predictions CPU is good enough. The minimum RAM required is 2GB . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyPDmcF7Mzyx",
        "colab_type": "text"
      },
      "source": [
        "**Changes in design**\n",
        "\n",
        "Our old system architecture can be seen here:\n",
        "https://drive.google.com/open?id=1XiwC_Q1bpNBWvgcXEqAOed1ArGzv_g41\n",
        "\n",
        "Our new system architecture can be seen here:\n",
        "https://drive.google.com/open?id=1rRdKpSmX46py3v1-CTqjtOrDXQcA25hv\n",
        "\n",
        "The major differences between our initial and current designs are that with the initial design the layers were not the right shapes to be combined for predicting the subclasses. We added extra layers so as to not lose information from preceding layers and to make the layers the right shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27BgfgTq7Lls",
        "colab_type": "text"
      },
      "source": [
        "# Hierarchical classifier first steps\n",
        "\n",
        "Let's get a CNN up and running. We want to load a pretrained model as *backbone*, specify custom classifier as *head*, and fine-tune the classifier on our data. The following are the libraries we are going to use in this project: numpy, matplotlib, torch, torchvision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyWuGfdCL5u0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyzZSbu8nrtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import tensor\n",
        "from torchvision import datasets, models\n",
        "\n",
        "np.random.seed(2) # for reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGYPHYDn4U2J",
        "colab_type": "text"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lkqduZW5xUL",
        "colab_type": "text"
      },
      "source": [
        "Load images and labels. We got the dataset from one of the fastai datasets. This dataset contains images of 37 breeds of dogs and cats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlLRkag1iO6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    from fastai.vision import untar_data, URLs, get_image_files\n",
        "    from PIL import Image\n",
        "    path = untar_data(URLs.PETS)\n",
        "    path_img = path/'images'\n",
        "    filenames = get_image_files(path_img)\n",
        "    images = [Image.open(filename).convert('RGB') for filename in filenames]\n",
        "\n",
        "    def get_labels(filenames):\n",
        "        import re\n",
        "        pat = r'([^/]+)_\\d+.jpg$'\n",
        "        pat = re.compile(pat)\n",
        "        return [pat.search(str(name)).group(1) for name in filenames]\n",
        "\n",
        "    return images, get_labels(filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_c5cu-64-Ki",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Wrote custom splitter because `sklearn`'s version was using tons of RAM for no apparent reason. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8AyLkEZtaUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_valid_split(x, y, valid_pct=0.33):\n",
        "    assert len(x) == len(y), 'len(x) != len(y)'\n",
        "    cutoff = int((1-valid_pct) * len(x))\n",
        "    x_train, y_train = x[:cutoff], y[:cutoff]\n",
        "    x_valid, y_valid = x[cutoff:], y[cutoff:]\n",
        "    return x_train, y_train, x_valid, y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baP2HQU1WmOz",
        "colab_type": "text"
      },
      "source": [
        "Now we process the images and transform them into tensors. The train and validation sets will be treated slightly differently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NGFL0tWlcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_images(x_train, x_valid):\n",
        "    from torchvision import transforms\n",
        "\n",
        "    def transform_train_images(x_train):\n",
        "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        return torch.stack([transform(image) for image in x_train]).cuda()\n",
        "\n",
        "    def transform_valid_images(x_valid):\n",
        "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        return torch.stack([transform(image) for image in x_valid]).cuda()\n",
        "\n",
        "    return transform_train_images(x_train), transform_valid_images(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBL7j_knhir",
        "colab_type": "text"
      },
      "source": [
        "Now convert class names to ints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjaY1jBU7l5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def names_to_ints(y_train, y_valid, class_names):\n",
        "    class_dict = dict((class_name, idx) for idx, class_name in enumerate(class_names))\n",
        "\n",
        "    def _names_to_ints(class_dict, labels):\n",
        "        tuples = []\n",
        "        for label in labels:\n",
        "            breed_int = class_dict[label]\n",
        "            kind_int = 0 if label[0].isupper() else 1 # 0 for cats, 1 for dogs\n",
        "            tuples.append((breed_int, kind_int))\n",
        "        return torch.tensor(tuples).cuda()\n",
        "    \n",
        "    return _names_to_ints(class_dict, y_train), _names_to_ints(class_dict, y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLQXNRub4biX",
        "colab_type": "text"
      },
      "source": [
        "`DataLoader` will manage batches and do the shuffling for us. Note that since we aren't training the validation set, we don't need to store the gradients. We have 2x the memory available, so we can double the batch size and speed up training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97TbOjby9W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloaders(x_train, y_train, x_valid, y_valid, batchsize=64):\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "    bs = batchsize\n",
        "    train_ds = TensorDataset(x_train, y_train)\n",
        "    valid_ds = TensorDataset(x_valid, y_valid)\n",
        "    train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, pin_memory=False)\n",
        "    valid_dl = DataLoader(valid_ds, bs*2, shuffle=False, pin_memory=False)\n",
        "    return train_dl, valid_dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0EmPshjmblW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataBunch:\n",
        "    def __init__(self, train_dl, valid_dl, class_names):\n",
        "        self.train_dl = train_dl\n",
        "        self.valid_dl = valid_dl\n",
        "        self.class_names = class_names\n",
        "\n",
        "def get_data():\n",
        "    images, labels = load_data()\n",
        "    class_names = sorted(set(labels))\n",
        "    x_train, y_train, x_valid, y_valid = train_valid_split(images, labels)\n",
        "    x_train, x_valid = transform_images(x_train, x_valid)\n",
        "    y_train, y_valid = names_to_ints(y_train, y_valid, class_names)\n",
        "    train_dl, valid_dl = get_dataloaders(x_train, y_train, x_valid, y_valid)\n",
        "    return DataBunch(train_dl, valid_dl, class_names)\n",
        "\n",
        "data = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ra4ecJeEWSF",
        "colab_type": "text"
      },
      "source": [
        "### Load and run the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6X5BedIxuw",
        "colab_type": "text"
      },
      "source": [
        "This training loop is adapted from FastAI's Lesson 8 notebook. It's very simple, lacking regularization and visualization tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECrdUnmJI2IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl): \n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout here\n",
        "        model.train()\n",
        "        for images, labels in train_dl:\n",
        "            child_labels = labels[:, 0]\n",
        "            parent_labels = labels[:, 1]\n",
        "            \n",
        "            images.to(device)\n",
        "            child_labels.to(device)\n",
        "            parent_labels.to(device)\n",
        "            child_pred, parent_pred = model(images)\n",
        "\n",
        "            dist = torch.t(torch.stack(37*[parent_labels]))\n",
        "            dist = torch.where(dist > 0, dogs64, cats64)\n",
        "\n",
        "            loss = (loss_func(child_pred, child_labels) +\n",
        "                    loss_func(parent_pred, parent_labels) +\n",
        "                    torch.kl_div(child_pred, dist))\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss, child_acc, parent_acc = 0.,0.,0.\n",
        "            for images, labels in valid_dl:\n",
        "                child_labels = labels[:, 0]\n",
        "                parent_labels = labels[:, 1]\n",
        "                \n",
        "                images.to(device)\n",
        "                child_labels.to(device)\n",
        "                parent_labels.to(device)\n",
        "                child_pred, parent_pred = model(images)\n",
        "\n",
        "                loss = (loss_func(child_pred, child_labels) +\n",
        "                        loss_func(parent_pred, parent_labels))\n",
        "\n",
        "                tot_loss   += loss\n",
        "                child_acc  += accuracy(child_pred, child_labels)\n",
        "                parent_acc += accuracy(parent_pred, parent_labels)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, child_acc/nv, parent_acc/nv)\n",
        "    return tot_loss/nv, child_acc/nv, parent_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgYZmfdLadGG",
        "colab_type": "text"
      },
      "source": [
        "### Defining the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO44HVg6BZRL",
        "colab_type": "text"
      },
      "source": [
        "Let's start with modifying this so it outputs two predictions instead of one: child and parent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cSnLLwzrSXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source:\n",
        "# https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html#resnet18\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "#from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class HierResNet(ResNet):  \n",
        "    def __init__(self, block=BasicBlock, layers=[2,2,2,2], **kwargs):\n",
        "        super().__init__(block, layers, **kwargs)\n",
        "        # these lines no longer work because SSL certificate issues\n",
        "        #URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
        "        #state_dict = load_state_dict_from_url(URL, progress=True)\n",
        "        PATH = 'resnet18-5c106cde.pth'\n",
        "        self.load_state_dict(torch.load(PATH))\n",
        "        \n",
        "        # freeze the CNN\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        num_ftrs = self.fc.in_features\n",
        "        \n",
        "        # child layers\n",
        "        self.fc = nn.Linear(num_ftrs, 512) # child branch\n",
        "        self.fc2 = nn.Linear(640, 37)\n",
        "        \n",
        "        # parent layers\n",
        "        self.fcp = nn.Linear(num_ftrs, 2) # parent class\n",
        "        self.fcp2 = nn.Linear(2, 128)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # child branch\n",
        "        child = self.fc(x)               # 512 outs\n",
        "        \n",
        "        # parent branch\n",
        "        parent_res = self.fcp(x)         # 2 outs\n",
        "        parent = self.fcp2(parent_res)   # 128 outs\n",
        "        \n",
        "        # merge branches\n",
        "        both = torch.cat((child, parent), 1)\n",
        "        child_res = self.fc2(both)       # 37 outs\n",
        "\n",
        "        return child_res, parent_res\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HierResNet()\n",
        "\n",
        "# load onto GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# define loss\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "# only update weights in fully connected layers\n",
        "params = []\n",
        "layers_to_update = [model.fc, model.fc2, model.fcp, model.fcp2]\n",
        "for layer in layers_to_update:\n",
        "    params.extend(list(layer.parameters()))\n",
        "optimizer = optim.Adam(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzdi5MBXw2nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,child_acc,parent_acc = fit(5, model, loss_func, optimizer, data.train_dl, data.valid_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFpS8nrzPVmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in data.train_dl:\n",
        "    child_labels = labels[:, 0]\n",
        "    parent_labels = labels[:, 1]\n",
        "\n",
        "    print(child_labels)\n",
        "    print(parent_labels)\n",
        "\n",
        "    images.to(device)\n",
        "    child_labels.to(device)\n",
        "    parent_labels.to(device)\n",
        "    child_pred, parent_pred = model(images)\n",
        "    print(child_pred[0])\n",
        "    print(parent_pred[0])\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kQcIqSKPZZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(child_pred[1])\n",
        "print(parent_pred[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhWRc7MZsSBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in data.train_dl:\n",
        "            child_labels = labels[:, 0]\n",
        "            parent_labels = labels[:, 1]\n",
        "            \n",
        "            images.to(device)\n",
        "            child_labels.to(device)\n",
        "            parent_labels.to(device)\n",
        "            child_pred, parent_pred = model(images)\n",
        "\n",
        "            dist = torch.t(torch.stack(37*[parent_labels]))\n",
        "            dist = torch.where(dist > 0, dogs64, cats64)\n",
        "\n",
        "            loss = torch.kl_div(child_pred, dist)\n",
        "            print(loss)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuO4nhnEzVoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUaoDZuxzbhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_pred[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYDRWl3Jzc2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrgNy1B11org",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_pred[0].softmax(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPulnM6_2IYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_pred[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WISV3v2L2sA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_pred[0].log_softmax(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFcZBcy13ASJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPcE2WybNiBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}